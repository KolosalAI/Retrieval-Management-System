# Kolosal AI Retrieval Management System
âš¡ All-in-one, fully-local LLM retrieval orchestration: parse, embed, search, deploy, done.

<div align="center">
  <img src="logo.svg" alt="Kolosal Logo" width="200" style="background-color: white; padding: 10px; border-radius: 8px;">
</div>

![Kolosal AI Retrieval Management System](rms.png)

## Overview
Kolosal AI Retrieval Management System is an integrated, all-in-one solution combining a powerful LLM inference engine, embedding engine, robust document parser, high-performance vector database, built-in internet search capability, and a centralized management dashboard to seamlessly orchestrate all components. This unified platform fulfills over 90% of your LLM integration requirements while ensuring complete local deployment, privacy, and data control.

![Kolosal AI RMS Overview](overview.png)

## Features

- MCP (Model Context Protocol)

- RAG (Retrieval-Augmented Generation)

- LLM & Embeddings Inference

- AI Agents

- Internet Search

- Dashboard
![Kolosal AI Dashboard](dashboard.jpg)

## Built On Top Of

- [Kolosal AI Inference Engine](https://github.com/KolosalAI/kolosal-server)

- [Qdrant Vector Database](https://github.com/qdrant/qdrant)

- [SearXNG Internet Search](https://github.com/searxng/searxng)

- [MarkItDown](https://github.com/microsoft/markitdown)

- [Docling](https://github.com/DS4SD/docling)

## Getting Started

## Contributing


## License
This project is licensed under the Apache 2.0 License - see the [LICENSE](LICENSE) file for details.